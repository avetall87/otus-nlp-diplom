{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avetall87/development/otus/diplom/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Добавляем импорты\n",
    "\n",
    "from gensim.models import FastText\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymorphy2\n",
    "import nltk  # Natural Language Toolkit - для загрузки стоп слов русского языка\n",
    "import re\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm  # прогресбарbincount\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # рабиваем данные на traint и test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем утилиты для работы с датасетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(r'[А-Яа-яA-zёЁ-]+')\n",
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return \" \".join(regex.findall(text)).lower()\n",
    "    except Exception as e:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_prepared_datasets(file_name) -> []:\n",
    "    result = []\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        for line in file.readlines():\n",
    "            # result.append(line.replace('\\n', ''))\n",
    "            result.append(line)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data, all_stop_words) -> []:\n",
    "    word_tokenizer = nltk.WordPunctTokenizer()\n",
    "\n",
    "    texts = []\n",
    "    targets = []\n",
    "\n",
    "    # инициализируем лемматизатор\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "    # поочередно проходим по всем новостям в списке\n",
    "    for item in tqdm(data):\n",
    "        text_lower = words_only(item)  # оставим только слова\n",
    "        tokens = word_tokenizer.tokenize(text_lower)  # разбиваем текст на слова\n",
    "\n",
    "        # удаляем пунктуацию и стоп-слова, а так же лемитизируем  слова\n",
    "        tokens = [morph.parse(word)[0].normal_form for word in tokens if\n",
    "                  (word not in all_stop_words and not word.isnumeric())]\n",
    "\n",
    "        # texts.append(tokens) # добавляем в предобработанный список\n",
    "        texts.append(' '.join(tokens))\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем предобработанные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/avetall87/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# загружаем список стоп-слов для русского\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_dataset_file_name = 'dataset/prepared_dataset.txt'\n",
    "\n",
    "# расширим список стоп-слов, словами, которые являеются стоп-словами в данной задаче\n",
    "add_stop_words = ['ао', 'оао', 'ооо']\n",
    "months = ['январь', 'февраль', 'март', 'апрель', 'май', 'июнь', 'июль', 'август', 'сентябрь', 'октябрь', 'ноябрь',\n",
    "            'декабрь', ]\n",
    "all_stop_words = stop_words + add_stop_words + months\n",
    "\n",
    "df = pd.read_csv('dataset/dataset.csv', sep=',', engine='python')\n",
    "\n",
    "y = df['title'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['подвижный сбор год днёвка деревня катеринный\\n',\n",
       " 'герой советский союз лётчик медноног скульптор м аникушин генеральный консул народный республика болгария ленинград вангел петрович трынок слева направо мастерская скульптор\\n',\n",
       " 'дважды герой соц труд смирнов избирательный участок время выборы местный совет народный судья\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = read_prepared_datasets(prepared_dataset_file_name)\n",
    "len(texts)\n",
    "texts[0:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем модель и создаем утилиты для работы с ней"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load AutoModel from huggingface model repository\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/sbert_large_nlu_ru\")\n",
    "model = AutoModel.from_pretrained(\"sberbank-ai/sbert_large_nlu_ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vector(text):\n",
    "    #Sentences we want sentence embeddings for\n",
    "    sentences = text\n",
    "\n",
    "    #Tokenize sentences\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=100, return_tensors='pt')\n",
    "\n",
    "    #Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    #Perform pooling. In this case, mean pooling\n",
    "    return mean_pooling(model_output, encoded_input['attention_mask'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем векторные представления для данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116000/116000 [2:57:05<00:00, 10.92it/s] \n"
     ]
    }
   ],
   "source": [
    "vectors = []\n",
    "for sent in tqdm(texts):\n",
    "    vectors.append(\n",
    "            np.nan_to_num(np.array(get_text_vector(sent.replace('\\n', ''))))[0]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vectors'] = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6_KffdPhotoDoc_65243</td>\n",
       "      <td>Подвижной сбор 1901 года.Дневка у деревни Кате...</td>\n",
       "      <td>[0.81877, -0.19550869, -0.6745616, 0.78428304,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6_KffdPhotoDoc_941</td>\n",
       "      <td>Герой Советского Союза, летчик В.А.Медноногов,...</td>\n",
       "      <td>[0.46559736, -0.09520167, -0.76400936, -0.5952...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6_KffdPhotoDoc_6002</td>\n",
       "      <td>Дважды Герой Соц.Труда В.А.Смирнов на избирате...</td>\n",
       "      <td>[1.0683433, 0.024790067, -1.0115333, 0.4484961...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6_KffdPhotoDoc_65096</td>\n",
       "      <td>Вид сверху на казармы полка.</td>\n",
       "      <td>[0.21965662, -0.90563685, -0.2903497, 0.410068...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6_KffdPhotoDoc_95843</td>\n",
       "      <td>Генерал казачьих войск Холмский (сидит 2-ой сл...</td>\n",
       "      <td>[0.36982885, -0.26320565, -0.39439437, 0.20517...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6_KffdPhotoDoc_66745</td>\n",
       "      <td>Секции армокаркаса у подножия бокового корпуса.</td>\n",
       "      <td>[0.93024564, -0.250312, 0.70953155, 0.17610043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6_KffdPhotoDoc_58622</td>\n",
       "      <td>Кавалерийские части на параде войск проходят м...</td>\n",
       "      <td>[0.35548604, -0.29775593, -0.8189927, -0.61472...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6_KffdPhotoDoc_71835</td>\n",
       "      <td>Пассажирский поезд прибыл на Финляндский вокзал.</td>\n",
       "      <td>[-0.14502977, -0.19560207, -0.6273539, -0.1823...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6_KffdPhotoDoc_112688</td>\n",
       "      <td>Хирург, профессор, орденоносец И.П.Виноградов ...</td>\n",
       "      <td>[0.19173354, -0.38422066, -0.349715, -0.097659...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6_KffdPhotoDoc_18624</td>\n",
       "      <td>Скульптор В.Б. Пинчук за работой над скульптур...</td>\n",
       "      <td>[0.5630582, -0.27837518, -1.0099745, -0.430176...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title                                               text   \n",
       "0   6_KffdPhotoDoc_65243  Подвижной сбор 1901 года.Дневка у деревни Кате...  \\\n",
       "1     6_KffdPhotoDoc_941  Герой Советского Союза, летчик В.А.Медноногов,...   \n",
       "2    6_KffdPhotoDoc_6002  Дважды Герой Соц.Труда В.А.Смирнов на избирате...   \n",
       "3   6_KffdPhotoDoc_65096                       Вид сверху на казармы полка.   \n",
       "4   6_KffdPhotoDoc_95843  Генерал казачьих войск Холмский (сидит 2-ой сл...   \n",
       "5   6_KffdPhotoDoc_66745    Секции армокаркаса у подножия бокового корпуса.   \n",
       "6   6_KffdPhotoDoc_58622  Кавалерийские части на параде войск проходят м...   \n",
       "7   6_KffdPhotoDoc_71835   Пассажирский поезд прибыл на Финляндский вокзал.   \n",
       "8  6_KffdPhotoDoc_112688  Хирург, профессор, орденоносец И.П.Виноградов ...   \n",
       "9   6_KffdPhotoDoc_18624  Скульптор В.Б. Пинчук за работой над скульптур...   \n",
       "\n",
       "                                             vectors  \n",
       "0  [0.81877, -0.19550869, -0.6745616, 0.78428304,...  \n",
       "1  [0.46559736, -0.09520167, -0.76400936, -0.5952...  \n",
       "2  [1.0683433, 0.024790067, -1.0115333, 0.4484961...  \n",
       "3  [0.21965662, -0.90563685, -0.2903497, 0.410068...  \n",
       "4  [0.36982885, -0.26320565, -0.39439437, 0.20517...  \n",
       "5  [0.93024564, -0.250312, 0.70953155, 0.17610043...  \n",
       "6  [0.35548604, -0.29775593, -0.8189927, -0.61472...  \n",
       "7  [-0.14502977, -0.19560207, -0.6273539, -0.1823...  \n",
       "8  [0.19173354, -0.38422066, -0.349715, -0.097659...  \n",
       "9  [0.5630582, -0.27837518, -1.0099745, -0.430176...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dataset/vectors.npy', np.array(list(vectors), dtype=np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path_or_buf='dataset/vectors.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 3307.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "м  так    так р  н н  м  м быть  так быть\n",
      "{'weight': '0.3772731423377991', 'entity_chiper': '6_KffdPhotoDoc_6890', 'raw text': 'М.И.Калинин (сидит в центре) и В.М.Молотов среди учатников конного пробега Ашхабад-Москва.'}\n",
      "{'weight': '0.3751116693019867', 'entity_chiper': '6_KffdPhotoDoc_33672', 'raw text': 'Фасад дома № 116/2 - угол Знаменской улицы, 2.'}\n",
      "{'weight': '0.37474656105041504', 'entity_chiper': '6_KffdPhotoDoc_40569', 'raw text': 'Кочегарка электростанции.'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "search_query = 'В каком то странном месте'.lower()\n",
    "query = np.nan_to_num(np.array(get_text_vector(search_query)))\n",
    "\n",
    "query = np.array(query)\n",
    "query = np.nan_to_num(query)\n",
    "\n",
    "cosine_similarities = pd.Series(cosine_similarity(query, vectors).flatten())\n",
    "\n",
    "for i,j in cosine_similarities.nlargest(3).items():\n",
    "  print({'weight':str(j), 'entity_chiper':df.title.iloc[i], 'raw text':df.text.iloc[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpairwise\u001b[39;00m \u001b[39mimport\u001b[39;00m cosine_similarity\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m request \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan_to_num(np\u001b[39m.\u001b[39marray(get_text_vector(\u001b[39m'\u001b[39m\u001b[39mЛуна\u001b[39m\u001b[39m'\u001b[39m)))\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(request)\n\u001b[1;32m      7\u001b[0m db \u001b[39m=\u001b[39m [\n\u001b[1;32m      8\u001b[0m     np\u001b[39m.\u001b[39mnan_to_num(np\u001b[39m.\u001b[39marray(get_text_vector(\u001b[39m'\u001b[39m\u001b[39mПодвижной сбор 1901 года.Дневка у деревни Катеринен\u001b[39m\u001b[39m'\u001b[39m))),\n\u001b[1;32m      9\u001b[0m     np\u001b[39m.\u001b[39mnan_to_num(np\u001b[39m.\u001b[39marray(get_text_vector(\u001b[39m'\u001b[39m\u001b[39mВид сверху на казармы полка\u001b[39m\u001b[39m'\u001b[39m)))\n\u001b[1;32m     10\u001b[0m     ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "request = np.nan_to_num(np.array(get_text_vector('Луна')))\n",
    "print(request)\n",
    "\n",
    "db = [\n",
    "    np.nan_to_num(np.array(get_text_vector('Подвижной сбор 1901 года.Дневка у деревни Катеринен'))),\n",
    "    np.nan_to_num(np.array(get_text_vector('Вид сверху на казармы полка')))\n",
    "    ]\n",
    "print(db)\n",
    "\n",
    "print(db[0])\n",
    "print(db[0][0])\n",
    "\n",
    "result = []\n",
    "\n",
    "for item in db:\n",
    "    result.append(item[0])\n",
    "\n",
    "cosine_similarities = pd.Series(cosine_similarity(request, result).flatten())\n",
    "print(cosine_similarities)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQUAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load AutoModel from huggingface model repository\n",
    "from transformers import pipeline, AutoModelForQuestionAnswering\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./model/tokenizer_ru_bert/\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"./model/pretrained_ru_bert_sbersquad/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Кто возлогает цветы у памятника Ленину?\"\n",
    "context = \"Пионеры ставят корзины с цветами к подножию монумента В.И.Ленина на площади Ленина у Финляндского вокзала.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9158473610877991, 'start': 0, 'end': 7, 'answer': 'Пионеры'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"./model/pretrained_ru_bert_sbersquad/\")\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\", model=model,tokenizer=tokenizer)\n",
    "question_answerer(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
